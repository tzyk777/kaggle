{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\zeyang\\Miniconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "D:\\Users\\zeyang\\Miniconda3\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor  #GBM algorithm\n",
    "from sklearn import cross_validation, metrics  #Additional scklearn functions\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "del df['id']\n",
    "dummy_df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [c for c in dummy_df.columns if c != 'loss']\n",
    "target = dummy_df['loss'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def modelfit(model, train_data, features, performCV=True, cv_folds=5, printFeatureImportance=True):\n",
    "    model.fit(train_data[features], train_data['loss'])\n",
    "    \n",
    "    predictions = model.predict(train_data[features])\n",
    "    if performCV:\n",
    "        #score_func = make_scorer(metrics.mean_squared_error, greater_is_better=False)\n",
    "        cv_score = cross_validation.cross_val_score(model, train_data[features], \n",
    "                                                    train_data['loss'], cv=cv_folds,\n",
    "                                                    n_jobs=4, scoring='neg_mean_squared_error',\n",
    "                                                    )\n",
    "    \n",
    "    print('Mean square error {}'.format(metrics.mean_squared_error(train_data['loss'].values, predictions)))\n",
    "    \n",
    "    if performCV:\n",
    "        print('CV Score: Mean - {} | Std - {} | Min - {} | Max - {}'.format(\n",
    "            -np.mean(cv_score),\n",
    "            np.std(cv_score),\n",
    "            -np.max(cv_score),\n",
    "            -np.min(cv_score)))\n",
    "        \n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(model.feature_importances_, features).sort_values(ascending=False)[:10]\n",
    "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "        plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a gradient boosting model, there are 3 kinds of parmameters:<br>\n",
    "1. tree-specific\n",
    "2. boosting\n",
    "3. miscellaneous parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A general approach to train a GBM:<br>\n",
    "1. Choose a relatively high learning rate. Generally the default value of 0.1 works but somewhere between 0.05 to 0.2 should work for different problems\n",
    "2. Determine the optimum number of trees for this learning rate. This should range around 40-70. Remember to choose a value on which your system can work fairly fast. This is because it will be used for testing various scenarios and determining the tree parameters.\n",
    "3. Tune tree-specific parameters for decided learning rate and number of trees. Note that we can choose different parameters to define a tree and I’ll take up an example here.\n",
    "4. Lower the learning rate and increase the estimators proportionally to get more robust models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree specific parameters:\n",
    "1. min_samples_split = 500 : This should be ~0.5-1% of total values. Since this is imbalanced class problem, we’ll take a small value from the range.\n",
    "2. min_samples_leaf = 50 : Can be selected based on intuition. This is just used for preventing overfitting and again a small value because of imbalanced classes.\n",
    "3. max_depth = 8 : Should be chosen (5-8) based on the number of observations and predictors. This has 87K rows and 49 columns so lets take 8 here.\n",
    "4. max_features = ‘sqrt’ : Its a general thumb-rule to start with square root.\n",
    "5. subsample = 0.8 : This is a commonly used used start value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "1. http://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/slides/gradient_boosting.pdf\n",
    "2. https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "3. http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to train a GBM by using parameters selected based on intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'n_estimators': 60, 'learning_rate': 0.1, 'min_samples_split': 1800, \n",
    "          'min_samples_leaf': 50, 'max_depth': 8, 'max_features': 'sqrt', 'subsample': 0.8, \n",
    "          'random_state': 10, 'loss': 'ls'}\n",
    "model = GradientBoostingRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error 3842112.6796678584\n",
      "CV Score: Mean - 3952696.6976141683 | Std - 95185.57782344749 | Min - 3831775.6214171518 | Max - 4068635.2153117447\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtUAAAEnCAYAAABmAb/kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJqun/A/BdI/htQGA1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29882452ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelfit(model, dummy_df, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators = {'n_estimators':list(range(20,81,10))}\n",
    "model_params = {'learning_rate': 0.1, 'min_samples_split': 1800, \n",
    "                'min_samples_leaf': 50, 'max_depth': 8, 'max_features': 'sqrt', 'subsample': 0.8, \n",
    "                'random_state': 10, 'loss': 'ls'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=8,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=50,\n",
       "             min_samples_split=1800, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=10,\n",
       "             subsample=0.8, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=False, n_jobs=4,\n",
       "       param_grid={'n_estimators': [20, 30, 40, 50, 60, 70, 80]},\n",
       "       pre_dispatch='2*n_jobs', refit=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1 = GridSearchCV(estimator = GradientBoostingRegressor(**model_params), \n",
    "                        param_grid = estimators, scoring='neg_mean_squared_error',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(dummy_df[features], dummy_df['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: -4768669.01654, std: 124141.56583, params: {'n_estimators': 20},\n",
       "  mean: -4366829.62117, std: 120901.51594, params: {'n_estimators': 30},\n",
       "  mean: -4144515.53353, std: 109348.15004, params: {'n_estimators': 40},\n",
       "  mean: -4029902.79980, std: 103908.71091, params: {'n_estimators': 50},\n",
       "  mean: -3952696.69761, std: 95185.57782, params: {'n_estimators': 60},\n",
       "  mean: -3894807.27001, std: 90614.36102, params: {'n_estimators': 70},\n",
       "  mean: -3856532.56529, std: 89878.71891, params: {'n_estimators': 80}],\n",
       " {'n_estimators': 80},\n",
       " -3856532.5652858512)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal estimators for 0.1 learning rate is 80, which is the maximum value in the range, this indicates that the optimal estimators could be higher than 80. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators = {'n_estimators':list(range(80,201,20))}\n",
    "model_params = {'learning_rate': 0.1, 'min_samples_split': 1800, \n",
    "                'min_samples_leaf': 50, 'max_depth': 8, 'max_features': 'sqrt', 'subsample': 0.8, \n",
    "                'random_state': 10, 'loss': 'ls'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=8,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=50,\n",
       "             min_samples_split=1800, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=10,\n",
       "             subsample=0.8, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=False, n_jobs=4,\n",
       "       param_grid={'n_estimators': [80, 100, 120, 140, 160, 180, 200]},\n",
       "       pre_dispatch='2*n_jobs', refit=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch2 = GridSearchCV(estimator = GradientBoostingRegressor(**model_params), \n",
    "                        param_grid = estimators, scoring='neg_mean_squared_error',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(dummy_df[features], dummy_df['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: -3856532.56529, std: 89878.71891, params: {'n_estimators': 80},\n",
       "  mean: -3799621.98359, std: 81005.95344, params: {'n_estimators': 100},\n",
       "  mean: -3766044.94894, std: 81170.11998, params: {'n_estimators': 120},\n",
       "  mean: -3741065.33839, std: 79141.24886, params: {'n_estimators': 140},\n",
       "  mean: -3721595.73125, std: 77111.30915, params: {'n_estimators': 160},\n",
       "  mean: -3702576.74594, std: 73916.44904, params: {'n_estimators': 180},\n",
       "  mean: -3689287.25372, std: 72455.61686, params: {'n_estimators': 200}],\n",
       " {'n_estimators': 200},\n",
       " -3689287.253723553)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It still hits the maximum value 200. Try estimator numbers from 200 to 1000, but increase learning rate to 0.5 to save computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimators = {'n_estimators':list(range(200,1001,200))}\n",
    "model_params = {'learning_rate': 0.5, 'min_samples_split': 1800, \n",
    "                'min_samples_leaf': 50, 'max_depth': 8, 'max_features': 'sqrt', 'subsample': 0.8, \n",
    "                'random_state': 10, 'loss': 'ls'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.5, loss='ls', max_depth=8,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=50,\n",
       "             min_samples_split=1800, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=10,\n",
       "             subsample=0.8, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=False, n_jobs=4,\n",
       "       param_grid={'n_estimators': [200, 400, 600, 800, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch3 = GridSearchCV(estimator = GradientBoostingRegressor(**model_params), \n",
    "                        param_grid = estimators, scoring='neg_mean_squared_error',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(dummy_df[features], dummy_df['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: -3824580.26733, std: 40429.87340, params: {'n_estimators': 200},\n",
       "  mean: -3845968.91417, std: 25323.06381, params: {'n_estimators': 400},\n",
       "  mean: -3878790.68418, std: 28222.82928, params: {'n_estimators': 600},\n",
       "  mean: -3903485.39142, std: 22469.32946, params: {'n_estimators': 800},\n",
       "  mean: -3931857.99926, std: 11933.30456, params: {'n_estimators': 1000}],\n",
       " {'n_estimators': 200},\n",
       " -3824580.2673277715)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this batch of nestimators parameters, we can fix n to 200. Note 200 may still not be the optimal value because we have increased learning rate to 0.5 to reduce computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_estimators = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_depth and min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators = {'max_depth':list(range(5,16,2)), 'min_samples_split':list(range(1400,2400,200))}\n",
    "model_params = {'learning_rate': 0.1, 'min_samples_leaf': 50, \n",
    "                'max_features': 'sqrt', 'subsample': 0.8, \n",
    "                'random_state': 10, 'loss': 'ls',\n",
    "                'n_estimators': best_estimators}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=50,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=200, presort='auto', random_state=10,\n",
       "             subsample=0.8, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=False, n_jobs=4,\n",
       "       param_grid={'min_samples_split': [1400, 1600, 1800, 2000, 2200], 'max_depth': [5, 7, 9, 11, 13, 15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch4 = GridSearchCV(estimator = GradientBoostingRegressor(**model_params), \n",
    "                        param_grid = estimators, scoring='neg_mean_squared_error',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(dummy_df[features], dummy_df['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: -3792088.20105, std: 98500.33885, params: {'min_samples_split': 1400, 'max_depth': 5},\n",
       "  mean: -3793616.57114, std: 94738.92951, params: {'min_samples_split': 1600, 'max_depth': 5},\n",
       "  mean: -3802736.54866, std: 92812.55912, params: {'min_samples_split': 1800, 'max_depth': 5},\n",
       "  mean: -3813463.76624, std: 89896.02232, params: {'min_samples_split': 2000, 'max_depth': 5},\n",
       "  mean: -3810836.79696, std: 89579.44695, params: {'min_samples_split': 2200, 'max_depth': 5},\n",
       "  mean: -3709949.96364, std: 86780.24629, params: {'min_samples_split': 1400, 'max_depth': 7},\n",
       "  mean: -3716137.40800, std: 78662.02916, params: {'min_samples_split': 1600, 'max_depth': 7},\n",
       "  mean: -3706527.18591, std: 89415.06296, params: {'min_samples_split': 1800, 'max_depth': 7},\n",
       "  mean: -3718381.64372, std: 94866.16174, params: {'min_samples_split': 2000, 'max_depth': 7},\n",
       "  mean: -3733493.61820, std: 88833.78905, params: {'min_samples_split': 2200, 'max_depth': 7},\n",
       "  mean: -3661945.00814, std: 76236.69539, params: {'min_samples_split': 1400, 'max_depth': 9},\n",
       "  mean: -3676582.41630, std: 90083.25442, params: {'min_samples_split': 1600, 'max_depth': 9},\n",
       "  mean: -3680005.63514, std: 84922.15869, params: {'min_samples_split': 1800, 'max_depth': 9},\n",
       "  mean: -3692833.76853, std: 78653.96038, params: {'min_samples_split': 2000, 'max_depth': 9},\n",
       "  mean: -3686517.24667, std: 87182.87834, params: {'min_samples_split': 2200, 'max_depth': 9},\n",
       "  mean: -3638491.00665, std: 89470.77224, params: {'min_samples_split': 1400, 'max_depth': 11},\n",
       "  mean: -3649299.93976, std: 91397.67191, params: {'min_samples_split': 1600, 'max_depth': 11},\n",
       "  mean: -3661647.95400, std: 90705.29152, params: {'min_samples_split': 1800, 'max_depth': 11},\n",
       "  mean: -3653971.26393, std: 85700.36013, params: {'min_samples_split': 2000, 'max_depth': 11},\n",
       "  mean: -3666826.22594, std: 85801.63748, params: {'min_samples_split': 2200, 'max_depth': 11},\n",
       "  mean: -3633345.11772, std: 83319.23878, params: {'min_samples_split': 1400, 'max_depth': 13},\n",
       "  mean: -3640565.54080, std: 79127.00660, params: {'min_samples_split': 1600, 'max_depth': 13},\n",
       "  mean: -3642007.76002, std: 80832.05005, params: {'min_samples_split': 1800, 'max_depth': 13},\n",
       "  mean: -3639790.08762, std: 85858.47419, params: {'min_samples_split': 2000, 'max_depth': 13},\n",
       "  mean: -3662576.81203, std: 81756.55702, params: {'min_samples_split': 2200, 'max_depth': 13},\n",
       "  mean: -3615878.35696, std: 87221.48942, params: {'min_samples_split': 1400, 'max_depth': 15},\n",
       "  mean: -3627550.77893, std: 83186.64622, params: {'min_samples_split': 1600, 'max_depth': 15},\n",
       "  mean: -3626103.16852, std: 95124.63842, params: {'min_samples_split': 1800, 'max_depth': 15},\n",
       "  mean: -3638737.66204, std: 79688.54944, params: {'min_samples_split': 2000, 'max_depth': 15},\n",
       "  mean: -3652001.41707, std: 77896.22500, params: {'min_samples_split': 2200, 'max_depth': 15}],\n",
       " {'max_depth': 15, 'min_samples_split': 1400},\n",
       " -3615878.3569553746)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal max_depth is 15, but the optimal min_saples_split of this grid search is 1400, which is the minimum value in the range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_max_depth = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators = {'min_samples_split':list(range(100,1400,200))}\n",
    "model_params = {'learning_rate': 0.1, 'min_samples_leaf': 50, \n",
    "                'max_features': 'sqrt', 'subsample': 0.8, \n",
    "                'random_state': 10, 'loss': 'ls',\n",
    "                'n_estimators': best_estimators, 'max_depth': best_max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=15,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=50,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=200, presort='auto', random_state=10,\n",
       "             subsample=0.8, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=False, n_jobs=4,\n",
       "       param_grid={'min_samples_split': [100, 300, 500, 700, 900, 1100, 1300]},\n",
       "       pre_dispatch='2*n_jobs', refit=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch5 = GridSearchCV(estimator = GradientBoostingRegressor(**model_params), \n",
    "                        param_grid = estimators, scoring='neg_mean_squared_error',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(dummy_df[features], dummy_df['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: -3591559.66493, std: 80447.05881, params: {'min_samples_split': 100},\n",
       "  mean: -3599964.00613, std: 85984.77205, params: {'min_samples_split': 300},\n",
       "  mean: -3595052.37844, std: 83646.26926, params: {'min_samples_split': 500},\n",
       "  mean: -3600049.39910, std: 74367.36698, params: {'min_samples_split': 700},\n",
       "  mean: -3606893.70257, std: 80310.45445, params: {'min_samples_split': 900},\n",
       "  mean: -3610026.14683, std: 86581.18360, params: {'min_samples_split': 1100},\n",
       "  mean: -3616993.00829, std: 82602.83865, params: {'min_samples_split': 1300}],\n",
       " {'min_samples_split': 100},\n",
       " -3591559.6649335995)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_min_samples_split = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_parameters = {'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}\n",
    "model_params = {'learning_rate': 0.1, 'min_samples_leaf': 50, \n",
    "                'max_features': 'sqrt', 'min_samples_split': best_min_samples_split,\n",
    "                'random_state': 10, 'loss': 'ls',\n",
    "                'n_estimators': best_estimators, 'max_depth': best_max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=15,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=50,\n",
       "             min_samples_split=40, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=200, presort='auto', random_state=10,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=False, n_jobs=4,\n",
       "       param_grid={'subsample': [0.6, 0.7, 0.75, 0.8, 0.85, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch7 = GridSearchCV(estimator = GradientBoostingRegressor(**model_params), \n",
    "                        param_grid = grid_parameters, scoring='neg_mean_squared_error',n_jobs=4,iid=False, cv=5)\n",
    "gsearch7.fit(dummy_df[features], dummy_df['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: -3616129.34031, std: 88840.25645, params: {'subsample': 0.6},\n",
       "  mean: -3601675.81786, std: 88907.99045, params: {'subsample': 0.7},\n",
       "  mean: -3601468.00289, std: 80435.01447, params: {'subsample': 0.75},\n",
       "  mean: -3591559.66493, std: 80447.05881, params: {'subsample': 0.8},\n",
       "  mean: -3589418.70110, std: 80290.06140, params: {'subsample': 0.85},\n",
       "  mean: -3584452.73371, std: 91638.60324, params: {'subsample': 0.9}],\n",
       " {'subsample': 0.9},\n",
       " -3584452.733710666)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch7.grid_scores_, gsearch7.best_params_, gsearch7.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_subsample = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_parameters = {'min_samples_leaf': list(range(30, 71, 10))}\n",
    "model_params = {'learning_rate': 0.1, 'subsample': 0.9,\n",
    "                'max_features': 'sqrt', 'min_samples_split': best_min_samples_split,\n",
    "                'random_state': 10, 'loss': 'ls',\n",
    "                'n_estimators': best_estimators, 'max_depth': best_max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=15,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=40, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=200, presort='auto', random_state=10,\n",
       "             subsample=0.9, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=False, n_jobs=4,\n",
       "       param_grid={'min_samples_leaf': [30, 40, 50, 60, 70]},\n",
       "       pre_dispatch='2*n_jobs', refit=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch8 = GridSearchCV(estimator = GradientBoostingRegressor(**model_params), \n",
    "                        param_grid = grid_parameters, scoring='neg_mean_squared_error',n_jobs=4,iid=False, cv=5)\n",
    "gsearch8.fit(dummy_df[features], dummy_df['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: -3593434.05566, std: 80642.49819, params: {'min_samples_leaf': 30},\n",
       "  mean: -3584346.54072, std: 81333.50725, params: {'min_samples_leaf': 40},\n",
       "  mean: -3584452.73371, std: 91638.60324, params: {'min_samples_leaf': 50},\n",
       "  mean: -3579687.16140, std: 79604.03572, params: {'min_samples_leaf': 60},\n",
       "  mean: -3586420.12107, std: 94328.09744, params: {'min_samples_leaf': 70}],\n",
       " {'min_samples_leaf': 60},\n",
       " -3579687.1614041217)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch8.grid_scores_, gsearch8.best_params_, gsearch8.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_min_samples_leaf = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have finished all the parameter tunning, the optimal values for each parameters are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_params = {'n_estimators': best_estimators, \n",
    "               'learning_rate': 0.1, \n",
    "               'min_samples_split': best_min_samples_split, \n",
    "               'min_samples_leaf': best_min_samples_leaf, \n",
    "               'max_depth': best_max_depth, \n",
    "               'max_features': 'sqrt', \n",
    "               'subsample': best_subsample, \n",
    "               'random_state': 10, \n",
    "               'loss': 'ls'}\n",
    "best_model = GradientBoostingRegressor(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error 2866644.7489400674\n",
      "CV Score: Mean - 3579687.1614041217 | Std - 79604.03572094227 | Min - 3468259.4194887825 | Max - 3687966.5542373657\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtUAAAEpCAYAAABcC96UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22c34a46a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelfit(best_model, dummy_df, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing this \"best model\" with the model we built based on intution.<br><br>\n",
    "Old model:<br>\n",
    "Mean square error 3842112.6796678584<br>\n",
    "CV Score: Mean - 3952696.6976141683<br><br>\n",
    "\n",
    "\"Best model\":<br>\n",
    "Mean square error 2866644.7489400674<br>\n",
    "CV Score: Mean - 3579687.1614041217"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281143</td>\n",
       "      <td>0.466591</td>\n",
       "      <td>0.317681</td>\n",
       "      <td>0.61229</td>\n",
       "      <td>0.34365</td>\n",
       "      <td>0.38016</td>\n",
       "      <td>0.377724</td>\n",
       "      <td>0.369858</td>\n",
       "      <td>0.704052</td>\n",
       "      <td>0.392562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836443</td>\n",
       "      <td>0.482425</td>\n",
       "      <td>0.443760</td>\n",
       "      <td>0.71330</td>\n",
       "      <td>0.51890</td>\n",
       "      <td>0.60401</td>\n",
       "      <td>0.689039</td>\n",
       "      <td>0.675759</td>\n",
       "      <td>0.453468</td>\n",
       "      <td>0.208045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.212308</td>\n",
       "      <td>0.325779</td>\n",
       "      <td>0.29758</td>\n",
       "      <td>0.34365</td>\n",
       "      <td>0.30529</td>\n",
       "      <td>0.245410</td>\n",
       "      <td>0.241676</td>\n",
       "      <td>0.258586</td>\n",
       "      <td>0.297232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.369930</td>\n",
       "      <td>0.342355</td>\n",
       "      <td>0.40028</td>\n",
       "      <td>0.33237</td>\n",
       "      <td>0.31480</td>\n",
       "      <td>0.348867</td>\n",
       "      <td>0.341872</td>\n",
       "      <td>0.592264</td>\n",
       "      <td>0.555955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302678</td>\n",
       "      <td>0.398862</td>\n",
       "      <td>0.391833</td>\n",
       "      <td>0.23688</td>\n",
       "      <td>0.43731</td>\n",
       "      <td>0.50556</td>\n",
       "      <td>0.359572</td>\n",
       "      <td>0.352251</td>\n",
       "      <td>0.301535</td>\n",
       "      <td>0.825823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9    ...        cont5  \\\n",
       "0   4    A    B    A    A    A    A    A    A    B    ...     0.281143   \n",
       "1   6    A    B    A    B    A    A    A    A    B    ...     0.836443   \n",
       "2   9    A    B    A    B    B    A    B    A    B    ...     0.718531   \n",
       "3  12    A    A    A    A    B    A    A    A    A    ...     0.397069   \n",
       "4  15    B    A    A    A    A    B    A    A    A    ...     0.302678   \n",
       "\n",
       "      cont6     cont7    cont8    cont9   cont10    cont11    cont12  \\\n",
       "0  0.466591  0.317681  0.61229  0.34365  0.38016  0.377724  0.369858   \n",
       "1  0.482425  0.443760  0.71330  0.51890  0.60401  0.689039  0.675759   \n",
       "2  0.212308  0.325779  0.29758  0.34365  0.30529  0.245410  0.241676   \n",
       "3  0.369930  0.342355  0.40028  0.33237  0.31480  0.348867  0.341872   \n",
       "4  0.398862  0.391833  0.23688  0.43731  0.50556  0.359572  0.352251   \n",
       "\n",
       "     cont13    cont14  \n",
       "0  0.704052  0.392562  \n",
       "1  0.453468  0.208045  \n",
       "2  0.258586  0.297232  \n",
       "3  0.592264  0.555955  \n",
       "4  0.301535  0.825823  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_test_df = pd.get_dummies(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_to_drop = [c for c in dummy_test_df.columns if c not in dummy_df.columns]\n",
    "columns_to_fill = [c for c in dummy_df.columns if c not in dummy_test_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_to_drop.remove('id')\n",
    "for c in columns_to_drop:\n",
    "    del dummy_test_df[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_to_fill.remove('loss')\n",
    "for c in columns_to_fill:\n",
    "    dummy_test_df[c] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features = dummy_test_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = best_model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.Series(predictions, index=dummy_test_df['id'])\n",
    "results = results.reset_index()\n",
    "results.columns = ['id', 'loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.to_csv('gbm_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score: 1166"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE: I made a mistake when training these models, that is, I forgot to combine training dataset and test dataset first then train the model. We need to make sure the training dataset has the same columns as the test dataset. I don't want to redo all the things again because it's really slow to find the optimal parameters. However there are couple of things we need to notice.<br>\n",
    "1. The number of estimators(trees) was set to 200. But this might not be the optimal value because we increased the learning rate to 0.5 when training these models, we changed it back to 0.1 when searching other optimal parameters though.\n",
    "2. min_samples_split might not be optimal because it was the minimum value in the range.\n",
    "3. We didn't CV learning rate. Probably we can try some smaller learning rates, however, it really takes time.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
